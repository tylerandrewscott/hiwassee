return(tempcorpus)
}
cleancorpus<-text_cleaner(cleandocs)
# Transform into a document-term matrix
dtm <- DocumentTermMatrix(cleancorpus,
control = list(removePunctuation = TRUE,
stopwords=TRUE,
weighting=weightTf))
# Use only the most frequently occuring words
ten_words<-findFreqTerms(dtm,lowfreq = 10)
dtm10<-DocumentTermMatrix(cleancorpus,
control = list(removePunctuation = TRUE,
stopwords=TRUE,
weighting=weightTf,
dictionary=ten_words
))
# Run an LDA model with 5 topics looks optimal
ap_lda5 <- LDA(dtm10, k = 5, control = list(seed = 41616), method="VEM")
macrotable<-terms(ap_lda5, k=10)
macrotable
stargazer(macrotable)
# What is the best model from a perplexity perspective?
model.perplexity<-c()
for(i in 2:20){
ap_lda <- LDA(dtm10, k = i, control = list(seed = 1234))
model.perplexity<-c(model.perplexity,perplexity(ap_lda))
}
plot(2:20,
model.perplexity,
xlab="Number of Topics",
ylab = "Perplexity")
lines(2:20,model.perplexity)
marginal.perplexity<-c()
for(i in 2:length(model.perplexity)){
marginal.perplexity<-c(marginal.perplexity,(model.perplexity[i]-model.perplexity[i-1])/model.perplexity[i-1])
}
index<-1:length(marginal.perplexity)
plot(index,marginal.perplexity, xlab="Number of Topics", ylab = "Marginal Perplexity (% Change)")
lo <- loess(marginal.perplexity~index)
lines(predict(lo), col='red', lwd=2)
lines(index,marginal.perplexity, col='grey', lwd=1)
setwd("~/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs")
png("perplexity.png")
plot(2:20,
model.perplexity,
xlab="Number of Topics",
ylab = "Perplexity")
lines(2:20,model.perplexity)
dev.off()
png("perplexity-macro.png")
plot(2:20,
model.perplexity,
xlab="Number of Topics",
ylab = "Perplexity",
main = "Macro Budget Statements")
lines(2:20,model.perplexity)
dev.off()
# Marginal perplexity
marginal.perplexity<-c()
for(i in 2:length(model.perplexity)){
marginal.perplexity<-c(marginal.perplexity,(model.perplexity[i]-model.perplexity[i-1])/model.perplexity[i-1])
}
index<-1:length(marginal.perplexity)
png("marginal-perplex-macro.png")
plot(index,marginal.perplexity, xlab="Number of Topics", ylab = "Marginal Perplexity (% Change)",
main = "Macro Budget Statements")
lo <- loess(marginal.perplexity~index)
lines(predict(lo), col='red', lwd=2)
lines(index,marginal.perplexity, col='grey', lwd=1)
dev.off()
posterior_inference <- posterior(ap_lda5)
posterior_topic_dist<-posterior_inference$topics # This is the distribution of topics for each document
statements
Control.Fiscal<-as.vector(posterior_topic_dist[,1])
Control.Current.Revenue<-as.vector(posterior_topic_dist[,2])
Control.Revenue.Projections<-as.vector(posterior_topic_dist[,3])
Control.General.Fund<-as.vector(posterior_topic_dist[,4])
Control.Staff.Funding<-as.vector(posterior_topic_dist[,5])
## Contra-costa county topics macro
Contra<-data.frame(
Topic.Proportions<-c(Control.Fiscal[15:19],
Control.Current.Revenue[15:19],
Control.Revenue.Projections[15:19],
Control.General.Fund[15:19],
Control.Staff.Funding[15:19]),
Category<-c(rep("Control: Fiscal",5),
rep("Control: Current Revenue",5),
rep("Control: Revenue Projections",5),
rep("Control: General Fund Projections",5),
rep("Control: Staff Funding Projections",5)),
Year<-c(2012:2016,
2012:2016,
2012:2016,
2012:2016,
2012:2016)
)
ggplot(data = Contra,
aes(x = Year, y = Topic.Proportions)) +
geom_line(aes(Year,Topic.Proportions,linetype=Category)) +
theme_classic() +
ggtitle("Contra Costa County Micro-Budget Statement",subtitle = "By Topic (Budget Function & Subfunction" )
Control.Fiscal<-as.vector(posterior_topic_dist[,1])
Control.Current.Revenue<-as.vector(posterior_topic_dist[,2])
Control.Revenue.Projections<-as.vector(posterior_topic_dist[,3])
Control.General.Fund<-as.vector(posterior_topic_dist[,4])
Control.Staff.Funding<-as.vector(posterior_topic_dist[,5])
## Contra-costa county topics macro
Contra<-data.frame(
Topic.Proportions<-c(Control.Fiscal[15:19],
Control.Current.Revenue[15:19],
Control.Revenue.Projections[15:19],
Control.General.Fund[15:19],
Control.Staff.Funding[15:19]),
Category<-c(rep("Control: Fiscal",5),
rep("Control: Current Revenue",5),
rep("Control: Revenue Projections",5),
rep("Control: General Fund Projections",5),
rep("Control: Staff Funding Projections",5)),
Year<-c(2012:2016,
2012:2016,
2012:2016,
2012:2016,
2012:2016)
)
ggplot(data = Contra,
aes(x = Year, y = Topic.Proportions)) +
geom_line(aes(Year,Topic.Proportions,linetype=Category)) +
theme_classic() +
ggtitle("Contra Costa County Micro-Budget Statement",subtitle = "By Topic (Budget Function & Subfunction" )
ggsave("contra-costa-macro-time.png")
## Time series plot Contra costa county categories
Contra2016<-data.frame(
Topic.Proportions<-c(management[19],planning[19],control[19]),
Category<-c(rep("Management",1),rep("Planning",1),rep("Control",1)),
Year<-c(2016,2016,2016)
)
ggplot(Contra2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Contra Costa County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
ggsave("contra-macro-pie.png")
## Contra-costa county topics macro
Contra<-data.frame(
Topic.Proportions<-c(Control.Fiscal[15:19],
Control.Current.Revenue[15:19],
Control.Revenue.Projections[15:19],
Control.General.Fund[15:19],
Control.Staff.Funding[15:19]),
Category<-c(rep("Control: Fiscal",5),
rep("Control: Current Revenue",5),
rep("Control: Revenue Projections",5),
rep("Control: General Fund Projections",5),
rep("Control: Staff Funding Projections",5)),
Year<-c(2012:2016,
2012:2016,
2012:2016,
2012:2016,
2012:2016)
)
ggplot(data = Contra,
aes(x = Year, y = Topic.Proportions)) +
geom_line(aes(Year,Topic.Proportions,linetype=Category)) +
theme_classic() +
ggtitle("Contra Costa County Micro-Budget Statement",subtitle = "By Topic (Budget Function & Subfunction" )
ggsave("contra-costa-macro-time.png")
## Time series plot Contra costa county categories
Contra2016<-data.frame(
Topic.Proportions<-c(management[19],planning[19],control[19]),
Category<-c(rep("Management",1),rep("Planning",1),rep("Control",1)),
Year<-c(2016,2016,2016)
)
ggplot(Contra2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Contra Costa County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
ggsave("contra-macro-pie.png")
ggplot(Contra2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Contra Costa County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
Contra2016<-data.frame(
Topic.Proportions<-c(management[19],planning[19],control[19]),
Category<-c(rep("Management",1),rep("Planning",1),rep("Control",1)),
Year<-c(2016,2016,2016)
)
ggplot(Contra2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Contra Costa County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
## Time series plot Contra costa county categories
Contra2016<-data.frame(
Topic.Proportions<-c(Control.Fiscal[19],Control.Current.Revenue[19],Control.Revenue.Projections[19],
Control.General.Fund[19], Control.Staff.Funding[19]),
Category<-c(rep("Control: Fiscal",1),
rep("Control: Current Revenue",1),
rep("Control: Revenue Projections",1),
rep("Control: General Fund Projections",1),
rep("Control: Staff Funding Projections",1)),
Year<-c(2016,2016,2016,2016,2016)
)
ggplot(Contra2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Contra Costa County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
ggsave("contra-macro-pie.png")
statements
## Pie plot yolo county categories
Yolo2016<-data.frame(
Topic.Proportions<-c(Control.Fiscal[92],Control.Current.Revenue[92],Control.Revenue.Projections[92],
Control.General.Fund[92], Control.Staff.Funding[92]),
Category<-c(rep("Control: Fiscal",1),
rep("Control: Current Revenue",1),
rep("Control: Revenue Projections",1),
rep("Control: General Fund Projections",1),
rep("Control: Staff Funding Projections",1)),
Year<-c(2016,2016,2016,2016,2016)
)
ggplot(Yolo2016, aes(x="", y=Topic.Proportions, fill=Category))+
geom_bar(width = 1, stat = "identity") + coord_polar("y", start=0) +
scale_fill_brewer(palette="Blues")+
theme_minimal() + ggtitle("Yolo County Budget Macro-Statement",
subtitle="% Devoted to Each Function, 2016") +
xlab("") + ylab("")
ggsave("yolo-macro-pie.png")
install.packages("tesseract")
?tesseract
??tesseract
library(tesseract)
?tesseract
text<-ocr("/Users/jason/Downloads/ExampleForBorjas.png")
text
text()
install.packages("abbyyR")
library(abbyyR)
?abbyyR
ocrFile(file_path = "/Users/jason/Downloads/ExampleForBorjas.png", output_dir = "/Users/jason/Downloads")
cat(text)
?tesseract
orig <- pdftools::pdf_text("R-intro.pdf")[1]
install.packages("pdftools")
library(pdftools)
orig <- pdftools::pdf_text("/Users/jason/Downloads/ExampleForBorjas.png")
img_file <- pdftools::pdf_convert("R-intro.pdf", format = 'tiff', pages = 1, dpi = 400)
orig <- pdftools::pdf_text("/Users/jason/Downloads/ExampleForBorjas.pdf")
orig
?pdf_text
orig <- pdf_text("/Users/jason/Downloads/ExampleForBorjas.pdf")
orig
img_file <- pdftools::pdf_convert("/Users/jason/Downloads/ExampleForBorjas.pdf", format = 'tiff', pages = 1, dpi = 400)
text <- ocr(img_file)
text
cat(text
)
print(text)
setapp(c("Newspaper-reader", "castro537"))
getAppInfo()
setapp(c("Newspaper-reader", "l8y7brG722k5dNZC9pVCmndy"))
getAppInfo()
submitImage(file_path="/Users/jason/Downloads/ExampleForBorjas.png", pdfPassword="")
ocrFile(file_path = "/Users/jason/Downloads/ExampleForBorjas.png", output_dir = "/Users/jason/Downloads")
getResults()
library(pacman)
# This loads and installs the packages you need at once
pacman::p_load(RTextTools, quanteda,
tm,SnowballC,foreign,plyr,twitteR,
slam,foreign,wordcloud,LiblineaR,e1071, topicmodels,readr,
stargazer,ggplot2)
# Load all the budget statements into R
#macro = "~/Dropbox/BudgetsTextAnalysis-PMRC2017/CleanData/Macro/"
#setwd(macro)
micro = "~/Dropbox/BudgetsTextAnalysis-PMRC2017/CleanData/Micro/"
setwd(micro)
statements = list.files()
# We want to create the variables: countyname,year,statementtype and read in the documents
countyname<-c()
year<-c()
statementtype<-c()
documents<-c()
for(i in 1:length(statements)){
temp<-unlist(strsplit(statements[i], "[.]"))
countyname<-c(countyname,temp[1])
year<-c(year,temp[2])
statementtype<-c(statementtype,"micro")
documents<-c(documents,read_file(paste(micro,statements[i],sep="")))
}
# Use regular expressions to clean up some elements of the documents
cleandocs<-c()
for(i in 1:length(documents)){
cleandocs[i]<-gsub("\xfc\xbe\x8d\x96\x90\xbc"," ",documents[i])
cleandocs[i]<-gsub("\r\n"," ",cleandocs[i])
cleandocs[i]<-gsub("\xfc\xbe\x8c\xa3\xa4\xbc"," ",cleandocs[i])
}
# Now we clean and preprocess the statements and prepare them for analysis
library(topicmodels)
# Preprocess the text
text_cleaner<-function(corpus){
tempcorpus = lapply(corpus,toString)
for(i in 1:length(tempcorpus)){
tempcorpus[[i]]<-iconv(tempcorpus[[i]], "ASCII", "UTF-8", sub="")
}
tempcorpus = lapply(tempcorpus, tolower)
tempcorpus<-Corpus(VectorSource(tempcorpus))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
#Removing all the special charecters and words
tempcorpus <- tm_map(tempcorpus, toSpace, "/")
tempcorpus <- tm_map(tempcorpus, toSpace, "@")
tempcorpus <- tm_map(tempcorpus, toSpace, "\\|")
tempcorpus <- tm_map(tempcorpus, toSpace, "#")
tempcorpus <- tm_map(tempcorpus, toSpace, "http")
tempcorpus <- tm_map(tempcorpus, toSpace, "https")
tempcorpus <- tm_map(tempcorpus, toSpace, ".com")
tempcorpus <- tm_map(tempcorpus, toSpace, "$")
tempcorpus <- tm_map(tempcorpus, removeNumbers)
# Remove english common stopwords
tempcorpus <- tm_map(tempcorpus, removeWords, stopwords("english"))
# Remove punctuation
tempcorpus <- tm_map(tempcorpus, removePunctuation)
# Eliminate extra white spaces
tempcorpus <- tm_map(tempcorpus, stripWhitespace)
# Stem the document
tempcorpus <- tm_map(tempcorpus, PlainTextDocument)
tempcorpus <- tm_map(tempcorpus,  stemDocument, "english")
# Remove uninformative high-frequency words
#tempcorpus <- tm_map(tempcorpus, toSpace, "budget")
tempcorpus <- tm_map(tempcorpus, toSpace, "million")
tempcorpus <- tm_map(tempcorpus, toSpace, "counti")
#tempcorpus <- tm_map(tempcorpus, toSpace, "fund")
tempcorpus <- tm_map(tempcorpus, toSpace, "also")
tempcorpus <- tm_map(tempcorpus, toSpace, "will")
tempcorpus <- tm_map(tempcorpus, toSpace, "board")
tempcorpus <- tm_map(tempcorpus, toSpace, "last")
#tempcorpus <- tm_map(tempcorpus, toSpace, "year")
return(tempcorpus)
}
cleancorpus<-text_cleaner(cleandocs)
# Transform into a document-term matrix
dtm <- DocumentTermMatrix(cleancorpus,
control = list(removePunctuation = TRUE,
stopwords=TRUE,
weighting=weightTf))
# Plot of word frequencies
dtmmatrix<-as.matrix(dtm)
termlist<-dtm$dimnames$Terms
frequencies<-c()
for(i in 1:length(termlist)){
frequencies<-c(frequencies,sum(dtmmatrix[,i]))
}
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>600,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-micro.png")
# Plot of word frequencies
dtmmatrix<-as.matrix(dtm)
termlist<-dtm$dimnames$Terms
frequencies<-c()
for(i in 1:length(termlist)){
frequencies<-c(frequencies,sum(dtmmatrix[,i]))
}
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>600,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-micro.png")
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>1000,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-micro.png")
df<-df[frequencies>2000,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-micro.png")
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>1500,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-micro.png")
library(pacman)
# This loads and installs the packages you need at once
pacman::p_load(RTextTools, quanteda,
tm,SnowballC,foreign,plyr,twitteR,
slam,foreign,wordcloud,LiblineaR,e1071, topicmodels,readr,
stargazer,ggplot2)
# Load all the budget statements into R
macro = "~/Dropbox/BudgetsTextAnalysis-PMRC2017/CleanData/Macro/"
setwd(macro)
#micro = "~/Dropbox/BudgetsTextAnalysis-PMRC2017/CleanData/Micro/"
#setwd(micro)
statements = list.files()
# We want to create the variables: countyname,year,statementtype and read in the documents
countyname<-c()
year<-c()
statementtype<-c()
documents<-c()
for(i in 1:length(statements)){
temp<-unlist(strsplit(statements[i], "[.]"))
countyname<-c(countyname,temp[1])
year<-c(year,temp[2])
statementtype<-c(statementtype,"macro")
documents<-c(documents,read_file(paste(macro,statements[i],sep="")))
}
# Use regular expressions to clean up some elements of the documents
cleandocs<-c()
for(i in 1:length(documents)){
cleandocs[i]<-gsub("\xfc\xbe\x8d\x96\x90\xbc"," ",documents[i])
cleandocs[i]<-gsub("\r\n"," ",cleandocs[i])
cleandocs[i]<-gsub("\xfc\xbe\x8c\xa3\xa4\xbc"," ",cleandocs[i])
}
# Now we clean and preprocess the statements and prepare them for analysis
library(topicmodels)
# Preprocess the text
text_cleaner<-function(corpus){
tempcorpus = lapply(corpus,toString)
for(i in 1:length(tempcorpus)){
tempcorpus[[i]]<-iconv(tempcorpus[[i]], "ASCII", "UTF-8", sub="")
}
tempcorpus = lapply(tempcorpus, tolower)
tempcorpus<-Corpus(VectorSource(tempcorpus))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
#Removing all the special charecters and words
tempcorpus <- tm_map(tempcorpus, toSpace, "/")
tempcorpus <- tm_map(tempcorpus, toSpace, "@")
tempcorpus <- tm_map(tempcorpus, toSpace, "\\|")
tempcorpus <- tm_map(tempcorpus, toSpace, "#")
tempcorpus <- tm_map(tempcorpus, toSpace, "http")
tempcorpus <- tm_map(tempcorpus, toSpace, "https")
tempcorpus <- tm_map(tempcorpus, toSpace, ".com")
tempcorpus <- tm_map(tempcorpus, toSpace, "$")
tempcorpus <- tm_map(tempcorpus, removeNumbers)
# Remove english common stopwords
tempcorpus <- tm_map(tempcorpus, removeWords, stopwords("english"))
# Remove punctuation
tempcorpus <- tm_map(tempcorpus, removePunctuation)
# Eliminate extra white spaces
tempcorpus <- tm_map(tempcorpus, stripWhitespace)
# Stem the document
tempcorpus <- tm_map(tempcorpus, PlainTextDocument)
tempcorpus <- tm_map(tempcorpus,  stemDocument, "english")
# Remove uninformative high-frequency words
#tempcorpus <- tm_map(tempcorpus, toSpace, "budget")
tempcorpus <- tm_map(tempcorpus, toSpace, "million")
tempcorpus <- tm_map(tempcorpus, toSpace, "counti")
#tempcorpus <- tm_map(tempcorpus, toSpace, "fund")
tempcorpus <- tm_map(tempcorpus, toSpace, "also")
tempcorpus <- tm_map(tempcorpus, toSpace, "will")
tempcorpus <- tm_map(tempcorpus, toSpace, "board")
tempcorpus <- tm_map(tempcorpus, toSpace, "last")
#tempcorpus <- tm_map(tempcorpus, toSpace, "year")
return(tempcorpus)
}
cleancorpus<-text_cleaner(cleandocs)
# Transform into a document-term matrix
dtm <- DocumentTermMatrix(cleancorpus,
control = list(removePunctuation = TRUE,
stopwords=TRUE,
weighting=weightTf))
# Plot of word frequencies
dtmmatrix<-as.matrix(dtm)
termlist<-dtm$dimnames$Terms
frequencies<-c()
for(i in 1:length(termlist)){
frequencies<-c(frequencies,sum(dtmmatrix[,i]))
}
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>1500,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-macro.png")
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>500,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-macro.png")
df<-data.frame(termlist,
frequencies)
df<-df[frequencies>400,]
p <- ggplot(df, aes(x = reorder(termlist, frequencies), y = frequencies)) +
geom_bar(aes(fill = frequencies), stat = "identity")
p + coord_flip() + labs(y= "Frequency", x="Processed Terms") + theme_classic() +
scale_fill_gradient("Count", low = "blue", high = "red")
ggsave("/Users/jason/Dropbox/BudgetsTextAnalysis-PMRC2017/Draft/figs/freqwstemming-notrunc-macro.png")
